{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('./data/trainning/0/Screenshot 2020-05-05 at 11.09.35 PM (1).png') # testing image\n",
    "img_arr = img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 250, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_arr.shape # checking dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 250, 250, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_arr = img_arr.reshape((1,) + img_arr.shape) # convert to required dimension (4)\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for batch in datagen.flow(img_arr, batch_size=5,save_to_dir=\"./data/gen_test\", save_prefix='test', save_format='png'):\n",
    "    count += 1\n",
    "    if count > 10: # generating 10 images\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating images loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen2 = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_aug(filepath,save_to,qty):\n",
    "    img = load_img('./'+filepath) # testing image\n",
    "    img_arr = img_to_array(img)\n",
    "    img_arr = img_arr.reshape((1,) + img_arr.shape) # convert to required dimension (4)\n",
    "    count = 0\n",
    "    for batch in datagen2.flow(img_arr, batch_size=5,save_to_dir=save_to, save_prefix='test', save_format='png'):\n",
    "        count += 1\n",
    "        if count > qty: # generating 10 images\n",
    "            print('Generated')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_iterator(path,save_to,qty):\n",
    "    for subdir, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            #print os.path.join(subdir, file)\n",
    "            filepath = subdir + os.sep + file\n",
    "\n",
    "            if filepath.endswith(\".png\"):\n",
    "                print (filepath)\n",
    "                keras_aug(filepath,save_to,qty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/trainning/0/Screenshot 2020-05-05 at 11.11.33 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.11.29 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.11.25 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.09.35 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.12.48 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.12.43 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.12.40 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.12.37 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.12.31 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.12.27 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.12.24 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.12.21 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.12.16 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.12.12 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.12.08 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.12.04 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.12.01 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.11.58 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.11.51 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.10.05 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.10.02 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.09.49 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.09.44 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.15.29 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.15.25 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.15.22 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.14.51 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.14.47 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.14.39 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.14.35 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.14.30 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.14.26 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.14.21 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.14.18 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.13.55 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.13.47 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.13.42 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.13.38 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.13.34 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.13.31 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.13.07 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.13.04 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.13.00 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.08.04 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.08.14 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.08.21 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.08.26 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.08.30 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.08.36 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.08.40 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.08.44 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.08.49 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.08.57 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.09.04 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.09.08 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.09.13 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.09.22 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.09.26 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.09.30 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.09.39 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.11.36 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.11.41 PM (1).png\n",
      "Generated\n",
      "data/trainning/0/Screenshot 2020-05-05 at 11.11.45 PM (1).png\n",
      "Generated\n"
     ]
    }
   ],
   "source": [
    "files_iterator('data/trainning/0','./data/keras_gen/trainning/0',5)\n",
    "# files_iterator('data/trainning/1','./data/keras_gen/trainning/1',5)\n",
    "# files_iterator('data/trainning/2','./data/keras_gen/trainning/2',5)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# files_iterator('data/testing/0','./data/keras_gen/testing/0',5)\n",
    "# files_iterator('data/testing/1','./data/keras_gen/testing/1',5)\n",
    "# files_iterator('data/testing/2','./data/keras_gen/testing/2',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files_iterator('data/testing/2','./data/keras_gen/testing/2',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
